{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\universidad\\4to\\1er semestre\\machine learning\\project\\add statistics\\actas-capitulares-de-la-habana\\preprocessing\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: opencv-python in e:\\universidad\\4to\\1er semestre\\machine learning\\project\\add statistics\\actas-capitulares-de-la-habana\\preprocessing\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in e:\\universidad\\4to\\1er semestre\\machine learning\\project\\add statistics\\actas-capitulares-de-la-habana\\preprocessing\\.venv\\lib\\site-packages (from opencv-python) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"prueba/binarized_1.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "filtered_image = cv2.medianBlur(gray_image, 3) \n",
    "cv2.imwrite(\"bin_median.png\", filtered_image)\n",
    "canny = cv2.Canny(filtered_image, 75, 150)\n",
    "cv2.imwrite(\"bin_median_cann.png\", canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "# kernel = np.ones((3,3))\n",
    "dilated = cv2.dilate(canny, kernel, iterations=3)\n",
    "eroded = cv2.erode(dilated, kernel, iterations=2)\n",
    "cv2.imwrite(\"bin_median_cann_morph.png\", eroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizing\t✓\n"
     ]
    }
   ],
   "source": [
    "!kraken -i bin_median_cann_morph.png output_image.png binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute '_no_nep50_warning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkraken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbinarization\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkraken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\kraken\\binarization.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (affine_transform, binary_dilation, gaussian_filter,\n\u001b[0;32m     28\u001b[0m                            percentile_filter)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zoom \u001b[38;5;28;01mas\u001b[39;00m _zoom\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkraken\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KrakenInputException\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\scipy\\ndimage\\__init__.py:152\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m=========================================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mMultidimensional image processing (:mod:`scipy.ndimage`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m \n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2003-2005 Peter J. Verveer\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Redistribution and use in source and binary forms, with or without\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_filters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fourier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interpolation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize_axis_index\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ni_support\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _nd_image\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:18\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     Optional,\n\u001b[0;32m     12\u001b[0m     Union,\n\u001b[0;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m     14\u001b[0m     TypeVar,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_namespace\n\u001b[0;32m     21\u001b[0m AxisError: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mException\u001b[39;00m]\n\u001b[0;32m     22\u001b[0m ComplexWarning: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mWarning\u001b[39;00m]\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\scipy\\_lib\\_array_api.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     is_array_api_obj,\n\u001b[0;32m     19\u001b[0m     size,\n\u001b[0;32m     20\u001b[0m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_asarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# To enable array API and strict array-like input validation\u001b[39;00m\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\scipy\\_lib\\array_api_compat\\numpy\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mabs\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mround\u001b[39m\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\numpy\\testing\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestCase\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _private\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extbuild\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\numpy\\testing\\_private\\utils.py:465\u001b[0m\n\u001b[0;32m    461\u001b[0m         pprint\u001b[38;5;241m.\u001b[39mpprint(desired, msg)\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;129m@np\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_nep50_warning\u001b[49m()\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21massert_almost_equal\u001b[39m(actual, desired, decimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, err_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    467\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m    Raises an AssertionError if two items are not equal up to desired\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    precision.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    533\u001b[0m \n\u001b[0;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Hide traceback for py.test\u001b[39;00m\n",
      "File \u001b[1;32me:\\Universidad\\4to\\1er semestre\\Machine Learning\\Project\\Add statistics\\Actas-Capitulares-de-la-Habana\\Preprocessing\\.venv\\Lib\\site-packages\\numpy\\__init__.py:427\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__dir__\u001b[39m():\n\u001b[0;32m    428\u001b[0m     public_symbols \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m|\u001b[39m __numpy_submodules__\n\u001b[0;32m    430\u001b[0m     )\n\u001b[0;32m    431\u001b[0m     public_symbols \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrixlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtests\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconftest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistutils\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     }\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute '_no_nep50_warning'"
     ]
    }
   ],
   "source": [
    "import kraken.binarization\n",
    "import kraken.lib\n",
    "from PIL import Image\n",
    "\n",
    "# Carga la imagen\n",
    "image = Image.open('bin_median_cann_morph.png')\n",
    "\n",
    "# Aplica binarización\n",
    "binary_image = kraken.binarization.nlbin(image)\n",
    "\n",
    "# Guarda la imagen binarizada\n",
    "binary_image.save('output_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"prueba/input.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite(\"gray_image.png\", gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_grayscale(image_path, red_weight=0.1, green_weight=0.1, blue_weight=0.8):\n",
    "    \"\"\"\n",
    "    Convierte una imagen a escala de grises usando pesos personalizados para los canales RGB.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Ruta de la imagen original.\n",
    "        red_weight (float): Peso para el canal rojo.\n",
    "        green_weight (float): Peso para el canal verde.\n",
    "        blue_weight (float): Peso para el canal azul.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Imagen en escala de grises personalizada.\n",
    "    \"\"\"\n",
    "    # Cargar la imagen en formato RGB\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error al cargar la imagen.\")\n",
    "        return None\n",
    "\n",
    "    # Convertir BGR a RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Separar los canales de color\n",
    "    blue, green, red = cv2.split(image)\n",
    "\n",
    "    # Aplicar la fórmula personalizada\n",
    "    grayscale_custom = (blue_weight * blue +\n",
    "                        green_weight * green +\n",
    "                        red_weight * red).astype(np.uint8)\n",
    "\n",
    "    return grayscale_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_grayscale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gray_image \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_grayscale\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprueba/Image-137.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray_image2.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, gray_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_grayscale' is not defined"
     ]
    }
   ],
   "source": [
    "gray_image = custom_grayscale(\"prueba/Image-137.jpg\")\n",
    "cv2.imwrite(\"gray_image2.png\", gray_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_image = cv2.resize(gray_image, (600, 900))\n",
    "# cv2.imwrite(\"resized_image.png\", resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "equalized_image = cv2.equalizeHist(gray_image)\n",
    "cv2.imwrite(\"denoised_image_eq2.png\", equalized_image)\n",
    "\n",
    "denoised_image = cv2.GaussianBlur(equalized_image, (11, 11), 0)\n",
    "cv2.imwrite(\"denoised_image2.png\", denoised_image)\n",
    "\n",
    "# smoothed = cv2.bilateralFilter(denoised_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "# cv2.imwrite(\"bil_denoised_image_eq2.png\", smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel = np.ones((5, 5), np.uint8)\n",
    "# cleaned = cv2.morphologyEx(smoothed, cv2.MORPH_CLOSE, kernel)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "# kernel = np.ones((3,3))\n",
    "eroded = cv2.erode(denoised_image, kernel, iterations=3)\n",
    "cv2.imwrite(\"eroded.png\", eroded)\n",
    "dilated = cv2.dilate(eroded, kernel, iterations=2)\n",
    "cv2.imwrite(\"morph.png\", dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kraken.binarization\n",
    "import kraken.lib\n",
    "from PIL import Image\n",
    "\n",
    "# Carga la imagen\n",
    "image = Image.open('eroded.png')\n",
    "\n",
    "# Aplica binarización\n",
    "binary_image = kraken.binarization.nlbin(image,0.45,0.3)\n",
    "\n",
    "# Guarda la imagen binarizada\n",
    "binary_image.save('eroded.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Aplicar filtro Gaussiano para suavizar la imagen (ajusta el kernel según sea necesario)\n",
    "# blurred = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "\n",
    "# Crear un mapa de vecindarios oscuros\n",
    "# Un píxel será \"oscuro\" si su valor está por debajo de un umbral\n",
    "dark_pixel_map = (smoothed < 100).astype(np.uint8)  # Ajusta el umbral según tu caso\n",
    "\n",
    "# Contar píxeles oscuros en la vecindad usando una convolución\n",
    "kernel = np.zeros((15, 15), np.uint8)  # Tamaño del vecindario\n",
    "dark_neighbors = cv2.filter2D(dark_pixel_map, -1, kernel)\n",
    "cv2.imwrite(\"dark_neighbors.png\", smoothed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image = cv2.medianBlur(denoised_image, 5) \n",
    "cv2.imwrite(\"denoised_image_median2.png\", denoised_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jack/Library/Python/3.10/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/z_/jz4f3stj0xq5g99z3sb19w3r0000gn/T/ipykernel_50356/2134230996.py\", line 1, in <module>\n",
      "    import kraken.binarization\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kraken/binarization.py\", line 32, in <module>\n",
      "    from kraken.lib.util import array2pil, get_im_str, is_bitonal, pil2array\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kraken/lib/util.py\", line 13, in <module>\n",
      "    from kraken.containers import BBoxLine\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kraken/containers.py\", line 30, in <module>\n",
      "    from kraken.lib.segmentation import compute_polygon_section\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kraken/lib/segmentation.py\", line 40, in <module>\n",
      "    from skimage.morphology import skeletonize\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/skimage/morphology/__init__.py\", line 9, in <module>\n",
      "    from .binary import binary_closing, binary_dilation, binary_erosion, binary_opening\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/skimage/morphology/binary.py\", line 9, in <module>\n",
      "    from .misc import default_footprint\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/skimage/morphology/misc.py\", line 9, in <module>\n",
      "    from .._shared._dependency_checks import is_wasm\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/skimage/_shared/_dependency_checks.py\", line 5, in <module>\n",
      "    has_mpl = is_installed(\"matplotlib\", \">=3.3\")\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/skimage/_shared/version_requirements.py\", line 58, in is_installed\n",
      "    actver = get_module_version(name)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/skimage/_shared/version_requirements.py\", line 32, in get_module_version\n",
      "    mod = __import__(module_name, fromlist=[module_name.rpartition('.')[-1]])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/ticker.py\", line 143, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    }
   ],
   "source": [
    "import kraken.binarization\n",
    "import kraken.lib\n",
    "from PIL import Image\n",
    "\n",
    "# Carga la imagen\n",
    "image = Image.open('bil_denoised_image_eq2.png')\n",
    "\n",
    "# Aplica binarización\n",
    "binary_image = kraken.binarization.nlbin(image, 0.4)\n",
    "\n",
    "# Guarda la imagen binarizada\n",
    "binary_image.save('output_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equalized_image2 = cv2.equalizeHist(smoothed)\n",
    "cv2.imwrite(\"eqeq.png\", equalized_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image = cv2.medianBlur(equalized_image, 11) \n",
    "cv2.imwrite(\"denoised_image_median2.png\", equalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_image = cv2.equalizeHist(filtered_image)\n",
    "cv2.imwrite(\"denoised_image_eq.png\", equalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(smoothed, 75, 150)\n",
    "cv2.imwrite(\"canny_image_aftergauss_eq3.png\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((5, 5), np.uint8)  # Kernel de 3x3\n",
    "# kernel = cv2.circle(kernel, (2,2), 2, 1)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "dilated = cv2.dilate(edges, kernel, iterations=2)\n",
    "cv2.imwrite(\"dilated_canny_image_aftergauss_eq.png\", dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(edges, kernel, iterations=1)\n",
    "cv2.imwrite(\"eroded_canny_image_aftergauss_eq.png\", eroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_image = cv2.equalizeHist(gray_image)\n",
    "filtered_image = cv2.medianBlur(equalized_image, 3)\n",
    "cv2.imwrite(\"equalized_image_median.png\", filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(filtered_image, 50, 150)\n",
    "cv2.imwrite(\"canny_image.png\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, binary_image = cv2.threshold(filtered_image, 100, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite(\"binary_image.png\", binary_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(image, 50, 150)\n",
    "cv2.imwrite(\"canny_image.png\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, otsu_binary = cv2.threshold(filtered_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imwrite(\"otsu_image.png\", binary_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_image = cv2.adaptiveThreshold(\n",
    "    filtered_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 2\n",
    ")\n",
    "cv2.imwrite(\"binarized_image.png\", binarized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_image_after_bin = cv2.medianBlur(binarized_image, 3) \n",
    "cv2.imwrite(\"denoised_image_median_afterbin.png\", filtered_image_after_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#no funciona bien\n",
    "coords = np.column_stack(np.where(binarized_image > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "else:\n",
    "    angle = -angle\n",
    "\n",
    "(h, w) = binarized_image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "rotated = cv2.warpAffine(binarized_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "cv2.imwrite(\"deskewed_image.png\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_removed = cv2.fastNlMeansDenoising(binarized_image, None, 10, 7, 21)\n",
    "cv2.imwrite(\"background_removed.png\", background_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(\n",
    "    binarized_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    ")\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    segment = binarized_image[y : y + h, x : x + w]\n",
    "    cv2.imwrite(f\"segment_{x}_{y}.png\", segment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
