% Informe de Proyecto % Autor: Tu Nombre % Fecha: Fecha actual

\documentclass[11pt,a4paper]{article}

\usepackage[spanish]{babel} 
\usepackage[utf8]{inputenc} 
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}

% Definición de estilos para los bloques y flechas
\tikzstyle{startstop} = [
  rectangle,
  rounded corners,
  minimum width=3cm,
  minimum height=1cm,
  text centered,
  draw=black
]
\tikzstyle{process} = [
  rectangle,
  minimum width=3.2cm,
  minimum height=1cm,
  text centered,
  draw=black
]
\tikzstyle{arrow} = [thick,->,>=stealth]


\title{Actas Capitulares de la Habana} 
\author{Edian Broche Castro \\ Roger Fuentes Rodr\'iguez \\ Kevin Manzano Rodr\'iguez \\ Massiel Paz Otaño \\ Jackson Claudio Vera Pineda} 
\date{}

\begin{document}

\maketitle

\tableofcontents

\section{Introducción}
\subsection{Objetivo del Proyecto} 

El objetivo de este proyecto es desarrollar una propuesta de transcripción y procesamiento de un conjunto de imágenes, para su posterior uso como dataset en futuros proyectos que identifiquen entidades nombradas y creen grafos de conocimiento.  

\subsection{Contexto}

Se dispone de una serie documental perteneciente al fondo Ayuntamiento de La Habana del Archivo Histórico de la Oficina del Historiador de la Ciudad de la Habana.

Esta serie documental se divide en dos grupos o subseries: los libros originales (1550 - 1898) y los libros trasuntados (1550 - 1809). Los primeros destacan por su riqueza de contenido y forma; los segundos reflejan la labor del Ayuntamiento para garantizar la perdurabilidad de este tipo documental, al ser copias realizadas en la segunda mitad del siglo XIX.

Las actas dejan la huella de una institución colonial y su devenir en el tiempo: el Ayuntamiento. En ellas se recogen los planteamientos y discusiones de aquellos problemas que interesaban a los pobladores del lugar, ya fueran de índole económica, política o social, reflejando los hechos más significativos de cada época.

Por el momento, se cuenta con el tomo 1 digitalizado, mientras que el resto se encuentra en proceso de digitalización.

\section{Metodología}
\subsection{Enfoque del Proyecto}

Existen múltiples herramientas para la transcripción de documentos históricos. Entre estas, destaca \href{https://www.transkribus.org/}{Transkribus}, recomendada por el cliente por su uso en trabajos anteriores. No obstante, debido al deterioro de los documentos y al tipo específico de tipografía, los resultados no han sido satisfactorios. El bajo \textbf{accuracy} reportado por dicha herramienta, creada por especialistas en el tema, indica la complejidad del problema.

\begin{center} 
\includegraphics[width=1.0\textwidth]{transkribus} 
\end{center}

En este proyecto se afrontan dos grandes dificultades: la falta de datos para entrenar un modelo que maneje español con tipografía \textit{procesal-cortesana}, y la complejidad propia de la tarea, que normalmente requiere la atención de un especialista (tipógrafo o paleógrafo).

Ante estas circunstancias, el proyecto se orienta hacia la búsqueda exhaustiva de datos clasificados, un procesamiento minucioso de las imágenes, el uso de varios OCR y un posprocesamiento apoyado en diccionarios del idioma y un LLM.

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[node distance=2.0cm]
    
    % Bloques principales
    \node (start) [startstop] {Inicio};
    \node (clean) [process, below of=start] {Limpieza de Imágenes};
    \node (segment) [process, below of=clean] {Segmentación de Líneas};
    
    % Tres OCR, dispuestos en forma triangular debajo de "segment"
    \node (ocr1) [process, below left of=segment, xshift=-1.5cm] {OCR 1};
    \node (ocr2) [process, below of=segment, yshift=-0.5cm] {OCR 2};
    \node (ocr3) [process, below right of=segment, xshift=1.5cm] {OCR 3};
    
    % LLM debajo de los tres OCR
    \node (llm) [process, below of=ocr2, yshift=-1.0cm] {LLM correcciones};

    \node (llm2) [process, below of=llm, yshift=-1.0cm] {LLM combinaciones};
    
    % Flechas lineales
    \draw [arrow] (start) -- (clean);
    \draw [arrow] (clean) -- (segment);
    
    % Flechas desde segment a cada OCR
    \draw [arrow] (segment) -- (ocr1);
    \draw [arrow] (segment) -- (ocr2);
    \draw [arrow] (segment) -- (ocr3);
    
    % Flechas desde cada OCR hasta el LLM
    \draw [arrow] (ocr1) -- (llm);
    \draw [arrow] (ocr2) -- (llm);
    \draw [arrow] (ocr3) -- (llm);
    \draw [arrow] (llm) -- (llm2);

    \end{tikzpicture}
    \caption{Diagrama de flujo con tres OCR que convergen en el LLM y un proceso de combinaciones.}
    \label{fig:workflow}
\end{figure}

\subsection{Recursos Utilizados}

Se ha elegido Python como lenguaje principal por su facilidad de acceso a bibliotecas de procesamiento de texto e imágenes. Entre las utilizadas destacan: \texttt{Kraken}, \texttt{PIL}, \texttt{TensorFlow}, \texttt{Numpy}, \texttt{matplotlib}, \texttt{scipy}, \texttt{spaCy}, \texttt{symspellpy}, \texttt{transformers}, \texttt{cv2} y \texttt{sam2}.

El espaciado entre palabras y líneas en la letra \textit{procesal cortesana} no era tan generoso como lo es en la escritura moderna. La densidad del texto era mayor, lo que daba a los documentos un aspecto más compacto. Este espaciado pequeño reflejaba la naturaleza de la escritura manual en la época, donde los escribientes trataban de maximizar el uso del espacio en el pergamino o el papel.

Dadas estas características la segmentación del texto en las imagenes en líneas o palabras sería una tarea difícil. Para comenzar usamos técnicas clásicas para segmentar imagenes como proyección de histogramas, e implementamos un algoritmo sencillo que básicamente reconoce líneas de texto según la densidad de pixeles en una cierta vecindad. Posteriormente en busca de mejores resultados usamos un modelo entrenado específicamentepara esta tarea, usando Kraken.

\begin{figure}[h]
  \centering
  \begin{minipage}{1.0\textwidth}
  \begin{minipage}[t]{0.45\textwidth}
  \includegraphics[width=\textwidth]{line_1.png}\\[2em]
  \includegraphics[width=\textwidth]{line_3.png}
  \end{minipage}
  \hfill
  \raisebox{-0.5\height}{\includegraphics[width=0.45\textwidth]{kraken_segmentation.png}}
  \caption{Segmentación de la imagen en líneas de texto usando Kraken.}
  \label{fig:tresfotosmodelos}
  \end{minipage}
  \end{figure}

Una vez segmentadas las imagenes en líneas pasamos al reconocimiento de caracteres, usando los siguientes OCR:

\texttt{SimpleHTR (Handwritten Text Recognition)} es un sistema de reconocimiento de texto escrito a mano (HTR) implementado con TensorFlow (TF) y entrenado en el conjunto de datos HTR de IAM. El modelo toma imágenes de palabras individuales o líneas de texto (varias palabras) como entrada y genera el texto reconocido. Tres cuartas partes de las palabras del conjunto de validación se reconocen correctamente y la tasa de error de caracteres ronda el 10\%. Dada la complejidad de la segmentación en las imágenes, ya que el texto está aglomerado y los trazos sobrepasan las líneas, no sería efectivo usar el modelo para reconocer palabras. Por lo tanto, usamos el modelo entrenado para reconocer líneas completas (\url{https://www.dropbox.com/s/7xwkcilho10rthn/line-model.zip?dl=1}). El modelo es una versión simplificada de un sistema HTR implementado en una tesis (\url{https://repositum.tuwien.ac.at/obvutwhs/download/pdf/2874742}). Consta de 5 capas CNN, 2 capas RNN (LSTM) y la capa de pérdida y decodificación CTC.

\texttt{bdd-wormser-scriptorium-abbreviated-0.2} Se entrenó el modelo con datos de licencia abierta de HTR-United desde el siglo XVII hasta el XXI.

Hasta donde sabemos, todos los datos siguen las mismas pautas de transcripción.

El superíndice se presenta con un \textasciicircum antes de los caracteres. En algún momento, se usaría \texttt{< >} para marcar el tachado.

\texttt{McCATMuS-nfd-nofix-V1} es un modelo de transcripción de documentos manuscritos, impresos y mecanografiados desde el siglo XVI hasta el siglo XXI. Basado en conjuntos de datos de instituciones y proyectos comprometidos con la ciencia abierta, McCATMuS proporciona un conjunto de datos interoperable que abarca más de 180 manuscritos en 7 idiomas diferentes (francés, latín, español, inglés, alemán, italiano y occitano). Incluye más de 118.000 líneas de texto y casi 4 millones de caracteres, abarcando un período desde principios del siglo XVI hasta la actualidad.

Todos los conjuntos de datos fueron corregidos automáticamente o, cuando fue preciso, manualmente, para corresponder a las directrices de transcripción CATMuS, disponibles aquí: \url{https://catmus-guidelines.github.io/}.

Las anotaciones en el conjunto de datos resultan de la extracción de diseño, extracción de líneas, escritura y transcripción de los creadores originales del conjunto de datos en la mayoría de los casos, o de correcciones automáticas o manuales realizadas por el curador del conjunto de datos moderno de CATMuS.

Este modelo fue entrenado en el conjunto de datos McCATMuS, con Kraken v.4.3.13, con normalización NFD Unicode y un tamaño de lote de 32 en 157 épocas.\\


Transcritas las líneas con diferentes OCR, usamos estas salidas para combinarlas intentando recuperar la mayor cantidad de texto posible, corregir errores ortográficos y dar coherencia usando un LLM.

El LLM utilizado es \texttt{Gemini}, principalmente por motivos económicos. Como diccionario de frecuencias se empleó \href{https://github.com/hermitdave/FrequencyWords/blob/master/content/2016/es/es_full.txt}{spanish frequency dictionary}, pues la creación de un diccionario a partir de obras antiguas resultaba muy limitada. El modelo de \texttt{spaCy} usado fue \texttt{es\_core\_news\_sm}.

\texttt{Gemini} adopta una arquitectura \textit{transformer} basada en autoatención, de forma similar a los LLM modernos. Además, se ha entrenado en un corpus mixto multilingüe que incluye español. Aunque no se especializa en español antiguo, su sólido manejo del idioma y su facilidad de uso resultaron decisivos.

Por contraste, \texttt{GPT-2} se centra mayoritariamente en inglés y requiere optimizaciones adicionales; \texttt{T5} (incluso en sus variantes \texttt{base} o \texttt{large}) demanda más recursos computacionales, encareciendo su uso continuo.

Por ello, se optó por \texttt{Gemini} como un equilibrio entre rendimiento y compatibilidad con el español, un factor esencial al manejar gran volumen de documentos y requerir un ciclo iterativo de corrección.

Para la recopilación de datos se comenzó con el \href{https://zenodo.org/records/1490009/files/Rodrigo%20corpus%201.0.0.tar.gz?download=1}{dataset de Rodrigo}, que abarca español antiguo pero tipografía gótica (no procesal-cortesana). Luego se recurrió al corpus \href{https://corpuscodea.es/}{CODEA}, con documentos anteriores a 1900 que incluyen imágenes, transcripciones paleográficas y versiones críticas. Tras filtrar por el tipo de letra requerida, el total se redujo a 546 documentos, lo cual demuestra la dificultad de obtener datos adecuados.\\

\section{Resultados}
\subsection{Logros Principales}

En la primera etapa se logra una mejora considerable de las imágenes, aplicando un pipeline de limpieza que las convierte a escala de grises e incluye varias técnicas de filtrado (filtro gaussiano para reducir ruido, ecualización de histograma para mejorar contraste, y operaciones morfológicas de erosión y dilatación para resaltar los trazos). Finalmente, se emplea la binarización de \texttt{Kraken}, con redes neuronales profundas y binarización adaptativa entrenada en documentos históricos. En la figura \ref{fig:tresfotosmodelo} se observa la evolución desde la imagen original hasta la binarizada.

Para tratar las manchas producidas por la antigüedad (tonos amarillos), se implementa un conversor personalizado a escala de grises que pondera \textit{r} y \textit{g} de forma distinta a la habitual, atenuando así el efecto amarillo.

\begin{figure}[h] 
\centering 
\begin{minipage}{1.0\textwidth} 
\includegraphics[width=0.32\textwidth]{original.jpg} 
\includegraphics[width=0.32\textwidth]{morph.jpg} 
\includegraphics[width=0.32\textwidth]{kraken.jpg} 
\caption{Original, en escala de grises con letra reforzada, e imagen binarizada.} 
\label{fig:tresfotosmodelo} 
\end{minipage} 
\end{figure}

También se evalúan algoritmos de detección de bordes como \textit{sobel}, \textit{Canny} y \textit{laplaciano}. El último no funciona bien por su sensibilidad a cambios drásticos pixel a pixel (papel vs. tinta). Sobel y Canny muestran algunos buenos resultados en ciertos documentos, como se aprecia en la figura \ref{fig:tresfotos}, pero no de modo uniforme.

\begin{figure}[h] 
\centering 
\begin{minipage}{1.0\textwidth} 
\includegraphics[width=0.32\textwidth]{CODEA-0205_2v.jpg} 
\includegraphics[width=0.32\textwidth]{canny_image_aftergauss_eq2.png} 
\includegraphics[width=0.32\textwidth]{photo_2025-01-27_21-34-01.jpg} 
\caption{Original, detección de bordes y operaciones morfológicas (de izquierda a derecha).} 
\label{fig:tresfotos} 
\end{minipage} 
\end{figure}

También se prueba el filtrado mediano para reducir el ruido “sal y pimienta” y el filtrado bilateral, sin mejoras significativas. La binarización mediante un umbral fijo no detecta bien la letra en zonas de sombra, y la binarización adaptativa convencional recupera demasiado ruido.\\

Tras la binarización, las imágenes pasan por dos procesos de segmentación: uno interno de \texttt{Kraken} y otro basado en proyección de histogramas. El primero ofrece resultados superiores. Para segmentaciones manuales se investiga \texttt{SAM2}, sin lograr automatización completa. Dicha herramienta es efectiva con líneas rectas, algo que no se cumple en manuscritos antiguos. Resultado obtenido hasta el momento por \texttt{SAM2}se muestra en las figuras \ref{fig:sam2} y \ref{fig:sam 2}.

\begin{figure}[h] 
\centering 
\begin{minipage}{1.0\textwidth} 
\includegraphics[width=0.32\textwidth]{source_image.png} 
\includegraphics[width=0.32\textwidth]{segmented_image.png} 
\caption{Imagen original con boxes aplicados manualmente, y la imagen segmentada a partir de estos} 
\label{fig:sam2} 
\end{minipage} 
\end{figure}

\begin{figure}[h] 
\centering 
\begin{minipage}{1.0\textwidth} 
\includegraphics[width=0.32\textwidth]{mask_2.png} 
\includegraphics[width=0.32\textwidth]{mask_22.png} 
\caption{Imágenes de varias segmentaciones} 
\label{fig:sam 2} 
\end{minipage} 
\end{figure}

Finalmente, la imagen segmentada se procesa con tres OCR distintos: \texttt{SimpleHTR}, \texttt{sinai-sam-rec-v4-best} y \texttt{McCATMuS-nfd-nofix-V1}. Los dos últimos aprovechan \texttt{Kraken}, mientras que \texttt{SimpleHTR} requiere una segmentación previa en líneas.

\subsection{Posprocesamiento y Combinación}

Después de extraer el texto con los distintos OCR, se procede a un posprocesamiento para mejorar la fidelidad de las transcripciones. Inspirándose en el dataset de CODEA, se adopta una transcripción crítica de los documentos. Dada la complejidad de los manuscritos y los errores de OCR, se implementa un pipeline que corrige errores ortográficos y refina la coherencia.

En primer lugar, se usa \texttt{spaCy} para segmentar el texto en \textit{tokens}, aislando palabras y símbolos no alfabéticos. Cada palabra se corrige con \texttt{SymSpell}, que se apoya en un diccionario de frecuencias para separar palabras unidas y reponer grafías correctas. Luego, un modelo generativo (\texttt{Gemini}) refina la semántica y el estilo, ayudando a mantener un tono cercano al español antiguo.

\textbf{Combinación de OCR con el LLM.}  
Para unificar las salidas de los tres OCR (\texttt{SimpleHTR}, \texttt{sinai-sam-rec-v4-best} y \texttt{McCATMuS-nfd-nofix-V1}), se emplea \texttt{Gemini} con un enfoque de “prompt colaborativo”. Este recibe:

\begin{itemize}
\item Texto A: salida del OCR 1  
\item Texto B: salida del OCR 2  
\item Texto C: salida del OCR 3
\end{itemize}

Se le indica que compare las tres versiones, identifique coincidencias y divergencias, corrija inconsistencias ortográficas o gramaticales, y produzca una transcripción unificada fiel al original histórico. Gracias a la base en español y la capacidad generativa, \texttt{Gemini} pondera cada fragmento, compensando errores de un OCR con aciertos de otro.

Por ejemplo:

\begin{enumerate}
    \item Essta es una prueva de ectraccion de teexto. Connoscida cosa sea a todos los queesta carta uieren como yo don Fferrando por la gracia de dios hey de Castiella
    \item Esta es una prueba de extracción de texto. Conocida cosa sea a todos los que esta carta vieren como yo don Fferrando por la gracia de Dios hay de Castilla
    \item Esta es una prueba de extracción de texto. Conocida cosa sea a todos aquellos que esta carta vieran, como yo, don Fernando, por la gracia de Dios, rey de Castilla.
\end{enumerate}

\subsection{Desafíos Superados}

Uno de los principales retos se observa en la segmentación, que precisa ajustar parámetros para optimizar los siguientes pasos. 

Además, la conservación del español antiguo complica el posprocesamiento. Al no existir un diccionario de frecuencias específico, se recurre a un LLM que, si bien no es perfecto, ofrece una aproximación plausible. Se evalúan \texttt{GPT-2}, \texttt{google/mt5-small} y \texttt{flax-community/spanish-t5-small}, pero fracasan por limitaciones de recursos o mala adaptación al dominio. Finalmente, \texttt{Gemini} cumple con la exigencia, equilibrando precisión y costo de uso.

\section{Conclusiones}
\subsection{Impacto del Proyecto}

Este proyecto se concibe para la transcripción de documentos históricos resguardados en la Oficina del Historiador. Inicialmente se cuenta con un tomo digitalizado, y a medida que se digitalicen los siguientes, se podrán aplicar directamente estas técnicas de transcripción y análisis. Asimismo, los resultados pueden servir de base para productos reutilizables, como herramientas que busquen entidades o información valiosa en estos manuscritos.

\subsection{Recomendaciones para Futuras Implementaciones}

Se sugiere explorar el uso de SAM2 en la segmentación de imágenes. También se recomienda entrenar o afinar (\textit{fine-tuning}) \texttt{SimpleHTR} y el modelo generativo para mejorar la precisión en español antiguo. Por último, \texttt{GPT-2} podría reutilizarse entrenándose específicamente en este dominio, lo que potencialmente derivaría en buenos resultados.

\bibliographystyle{plain} 
\bibliography{referencias}

\begin{thebibliography}{9}

    \bibitem{Avila2020corpus}
    Vicente Marcet Rodriguez,
    \textit{El copus de documentos de \'Avila del Hispanic Museum and Library (siglos XV y XVI). Descripci\'on y an\'alisis paleogr\'afico y gr\'afico-fonol\'ogico.}

    \bibitem{granet2018transfer}
    A. Granet, E. Morin, H. Mouchère, S. Quiniou, y C. Viard-Gaudin, 
    \textit{Transfer Learning for Handwriting Recognition on Historical Documents}, 
    ICPRAM, 2018.
    
    \bibitem{torres2025htr}
    S. Torres Aguilar, 
    \textit{Handwritten Text Recognition for Historical Documents using Visual Language Models and GANs}, 
    ArXiv, 2025.
    
    \bibitem{granell2018transcription}
    E. Granell, E. Chammas, L. Likforman-Sulem, C. D. Martínez-Hinarejos, C. Mokbel, y B. I. Cîrstea, 
    \textit{Transcription of Spanish Historical Handwritten Documents with Deep Neural Networks}, 
    Journal of Imaging, vol. 4, no. 15, 2018.
    
    \bibitem{survey_post_ocr}
    THI TUYET HAI NGUYEN, ADAM JATOWT, MICKAEL COUSTATY and ANTOINE DOUCET,
    \textit{Survey of Post-OCR Processing Approaches}, 
    2025.

    \bibitem{LightweightOCR}
    Yuning Du, Chenxia Li, Ruoyu Guo, Xiaoting Yin, Weiwei Liu,
    Jun Zhou, Yifan Bai, Zilin Yu, Yehua Yang, Qingqing Dang, Haoshuang Wang,
    \textit{PP-OCR: A Practical Ultra Lightweight OCR System}
    
    \bibitem{IJARSCT2023extraction}
    Prof. Anuradha Thorat, Mayur Zagade, Shivani More, Manish Pasalkar, Anand Narute,
    \textit{Research Paper on Text Extraction using OCR}, 
    IJARSCT, Volume 3, Issue 14, May 2023

    \bibitem{IJIREM2022extraction}
    Ojas Kumar Barawal, and Dr Yojna Arora,
    \textit{Text Extraction from Image}, 
    IJIREM, Volume 9, Issue 3, May 2022

\end{thebibliography}

\end{document}
